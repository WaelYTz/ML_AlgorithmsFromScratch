{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUmlAAH0xiG1",
    "outputId": "91d590db-a291-491b-a5d7-e39681081095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   age  weight smoker    risk\n",
      "0   25      70     No     Low\n",
      "1   45      85    Yes    High\n",
      "2   30      65     No     Low\n",
      "3   50      90    Yes    High\n",
      "4   35      75     No  Medium\n",
      "5   60      95    Yes    High\n",
      "6   28      68     No     Low\n",
      "7   40      80    Yes  Medium\n",
      "8   55      88    Yes    High\n",
      "9   33      72     No  Medium\n",
      "\n",
      "Training set:\n",
      "[[25 70  0]\n",
      " [40 80  1]\n",
      " [30 65  0]\n",
      " [33 72  0]\n",
      " [35 75  0]\n",
      " [50 90  1]\n",
      " [28 68  0]]\n",
      "\n",
      "Training set labels:\n",
      "[1 2 1 2 2 0 1]\n",
      "\n",
      "Testing set:\n",
      "[[55 88  1]\n",
      " [45 85  1]\n",
      " [60 95  1]]\n",
      "\n",
      "Testing set labels:\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Data Preparation\n",
    "# ---------------------------\n",
    "\n",
    "# Defining the dataset\n",
    "data = {\n",
    "    'age': [25, 45, 30, 50, 35, 60, 28, 40, 55, 33],\n",
    "    'weight': [70, 85, 65, 90, 75, 95, 68, 80, 88, 72],\n",
    "    'smoker': ['No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No'],\n",
    "    'risk': ['Low', 'High', 'Low', 'High', 'Medium', 'High', 'Low', 'Medium', 'High', 'Medium']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Encoding categorical variables\n",
    "# Encoding 'smoker' (Yes=1, No=0)\n",
    "df['smoker_encoded'] = df['smoker'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Encoding 'risk' classes\n",
    "# We'll map 'High' -> 0, 'Low' -> 1, 'Medium' -> 2\n",
    "risk_mapping = {'High': 0, 'Low': 1, 'Medium': 2}\n",
    "df['risk_encoded'] = df['risk'].map(risk_mapping)\n",
    "\n",
    "# Features and target\n",
    "X = df[['age', 'weight', 'smoker_encoded']].values\n",
    "y = df['risk_encoded'].values\n",
    "\n",
    "# Train-Test Split\n",
    "def train_test_split_custom(X, y, test_size=0.3, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    test_size = int(X.shape[0] * test_size)\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_custom(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\nTraining set:\")\n",
    "print(X_train)\n",
    "print(\"\\nTraining set labels:\")\n",
    "print(y_train)\n",
    "print(\"\\nTesting set:\")\n",
    "print(X_test)\n",
    "print(\"\\nTesting set labels:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-MNeHBRyaLR"
   },
   "source": [
    "# **Tree Decision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZeyQPtgyHyM",
    "outputId": "01c5dd91-0473-47bd-c805-d0916b8e769a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2. Decision Tree Implementation\n",
    "# ---------------------------\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _gini(self, y):\n",
    "\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - sum(p ** 2 for p in probabilities)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "\n",
    "        best_split = {'feature_index': None, 'threshold': None, 'score': float('inf')}\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                if len(y[left_mask]) < self.min_samples_split or len(y[right_mask]) < self.min_samples_split:\n",
    "                    continue\n",
    "\n",
    "                left_gini = self._gini(y[left_mask])\n",
    "                right_gini = self._gini(y[right_mask])\n",
    "                weighted_avg_gini = (len(y[left_mask]) * left_gini + len(y[right_mask]) * right_gini) / len(y)\n",
    "\n",
    "                if weighted_avg_gini < best_split['score']:\n",
    "                    best_split = {\n",
    "                        'feature_index': feature_index,\n",
    "                        'threshold': threshold,\n",
    "                        'score': weighted_avg_gini\n",
    "                    }\n",
    "        return best_split if best_split['score'] < float('inf') else None\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if depth == self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            return {'type': 'leaf', 'class': np.bincount(y).argmax()}\n",
    "\n",
    "        best_split = self._best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return {'type': 'leaf', 'class': np.bincount(y).argmax()}\n",
    "\n",
    "        left_mask = X[:, best_split['feature_index']] <= best_split['threshold']\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        return {\n",
    "            'type': 'node',\n",
    "            'feature_index': best_split['feature_index'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left': self._build_tree(X[left_mask], y[left_mask], depth + 1),\n",
    "            'right': self._build_tree(X[right_mask], y[right_mask], depth + 1),\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return np.array([self._predict_input(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_input(self, x, node):\n",
    "        \n",
    "        if node['type'] == 'leaf':\n",
    "            return node['class']\n",
    "        if x[node['feature_index']] <= node['threshold']:\n",
    "            return self._predict_input(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_input(x, node['right'])\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Training and Evaluation\n",
    "# ---------------------------\n",
    "\n",
    "# Initialize and train Decision Tree\n",
    "dt = DecisionTree(max_depth=3)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with Decision Tree\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_dt = np.sum(y_pred_dt == y_test) / len(y_test)\n",
    "print(\"\\nDecision Tree Accuracy:\", accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpUVU4BtyWrl"
   },
   "source": [
    "# **RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "55xM_Mo9yUh6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 3. Random Forest Implementation\n",
    "# ---------------------------\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=None, min_samples_split=2, max_features='sqrt'):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "\n",
    "            if self.max_features == 'sqrt':\n",
    "                n_features = int(np.sqrt(X.shape[1]))\n",
    "            elif self.max_features == 'log2':\n",
    "                n_features = int(np.log2(X.shape[1]))\n",
    "            elif isinstance(self.max_features, int):\n",
    "                n_features = self.max_features\n",
    "            else:\n",
    "                n_features = X.shape[1]\n",
    "\n",
    "            feature_indices = np.random.choice(X.shape[1], n_features, replace=False)\n",
    "            X_sample = X_sample[:, feature_indices]\n",
    "\n",
    "            # Train Decision Tree\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            tree.feature_indices = feature_indices \n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X[:, tree.feature_indices]) for tree in self.trees])\n",
    "        tree_preds = tree_preds.T\n",
    "\n",
    "        y_pred = [Counter(row).most_common(1)[0][0] for row in tree_preds]\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# Initialize and train Random Forest\n",
    "rf = RandomForest(n_trees=5, max_depth=3, max_features='sqrt')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with Random Forest\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = np.sum(y_pred_rf == y_test) / len(y_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEsDmlCiy8jS"
   },
   "source": [
    "Result:\n",
    "Decision Tree Accuracy: 1.0\n",
    "Random Forest Accuracy: 1.0 **bold text** **bold text**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
